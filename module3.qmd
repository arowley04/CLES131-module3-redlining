---
title: "Module 3: Redlining"
format: pdf
editor: source
editor_options: 
  chunk_output_type: console
---

```{r}
#| warning: false
library(sf) # simple features for R
# install.packages("terra")
library(terra) # spatial data analysis
library(tidyterra) #tidyverse methods for terra objects
library(tidyverse)
```

### Use of GitHub

Link to your forked GH repository: git@github.com:arowley04/CLES131-module3-redlining.git

### Use of Quarto

Link to your .qmd file: 

# Ecological consequences of redlining

In August 2020, [Christopher Schell](https://cjschell.com/about) and collegues published a review in *Science* on ['The ecological and evolutionary consequences of systemic racism in urban environments'](https://science.sciencemag.org/content/early/2020/08/12/science.aay4497) showing how systematic racism and classism has significant impacts on ecological and evolutionary processes within urban environments. Here, we combine spatial data to reproduce and extend an analysis from the paper.

## The vector data

We will use a vector dataset of redlining maps from [Mapping Inequality](https://dsl.richmond.edu/panorama/redlining), a project led by [Robert K. Nelson](https://americanstudies.richmond.edu/faculty/rnelson2/).

### Q1 (1 point)

Click 'Explore the Maps' to look at some cities and neighborhoods you are familiar with. Who is the intended audience of this data science project, and how are the data used to communicate understanding, insight, and knowledge? Why is this effective?

I chose Chicago, IL. I assume the intended audience of this data science project is modern day individuals interested in learning about the history of redlining in America. The map of Chicago created using the 1940 census data was likely intended for real estate developers, city planners, policy makers, investors/banks, and other individuals/organizations that played a role in redlining Chicago back in the mid 1900's. 

The polygons on the map represent different property types and categorized by most to least desirable for residential areas, which is denoted by color, and industrial and commercial areas are denoted by symbol. The color choice for assigning implied value to residential areas green (best), blue (still desirable), yellow (definitely declining), and red (hazardous) is effective because these colors have the same intuitive meaning to a diverse audience and can be easily identified on the map. 

The 'Note About This Data' describes how racial profiles were accounted by grouping different minorities together based on the 1940 city census, which is beneficial for users today to understand how the raw data was manipulated and represented on the map. This section suggests some potential bias in the representation of certain Asian demographics. Additionally, the "Context" and "Area Descriptions" provide a lot of useful background about the history of redlining in Chicago and the racial demogaphics within different delineated areas. 

### Q2 (1 point)

Create a `data/` folder in the root of your project and create five subfolders labeled with the city names from Fig. 2 of Schell et al. 2020. Because the spatial files will be large, add `data/` to the .gitignore file. 

Then, go back to the home page of [Mapping Inequality](https://dsl.richmond.edu/panorama/redlining) and select 'Download the Data'. Use the search bar to select and download spatial data for each city. Move the geojson file into the associated data subfolder. 

Import the geojson file into your R environment with the `st_read`()` function from sf. Check the structure of this object and see that it is a special type of data frame, allowing it to be manipulated with many of the functions you already know, including ggplot. 

Make a quick plot of your first city showing the "grade" in color using ggplot syntax and `geom_sf()`. Select a color scheme that better comports with redlining. 

```{r}
# Read in data 
baltimore <- st_read("data/baltimore/balt_geojson.json") 
baltimore  
st_crs(baltimore)

birmingham <- st_read("data/birmingham //birm_geojson.json") 
birmingham 
st_crs(birmingham)

indianapolis <- st_read("data/indianapolis//indy_geojson.json") 
indianapolis
st_crs(indianapolis)

minneapolis <- st_read("data/minneapolis/minn_geojson.json") 
minneapolis
st_crs(minneapolis)

pheonix <- st_read("data/pheonix/pho_geojson.json") 
pheonix
st_crs(pheonix)
```

```{r}
# Plot first city

# unique(baltimore$fill) #see original hex code for each "grade" in color
# baltimore[baltimore$fill == "#00000", ] #inspecting weird NA values
baltimore$grade[is.na(baltimore$grade)] <- "Industrial & Commercial" #assigning NA values as industrial/commercial areas

ggplot() +
  geom_sf(data = baltimore, aes(fill = grade)) +
  scale_fill_manual(values = c("A"="#76a865", 
                               "B"="#7cb5bd", 
                               "C"="#ffff00", 
                               "D"= "#d9838d",
                               "Industrial & Commercial"= "lightgrey"),
                    labels = c("A" = "Best",
                               "B" = "Still Desireable",
                               "C" = "Definitely Declining",
                               "D" = "Hazardous",
                               "Industrial & Commercial" = "Industrial & Commercial")) + 
  labs(title = "Baltimore, MD (1940) Redlining Map",
       subtitle = "GCS WGS84",
       fill = "Grade") +
  theme_bw()
```


## The raster data

We will also be calculating NDVI from the European Space Agency's [Sentinel-2 Mission](https://documentation.dataspace.copernicus.eu/Data/SentinelMissions/Sentinel2.html), specifically bands B4 (red) and B8 (near infrared). There are multiple steps to importing the data, which itself takes a long time, so please get an early start.

 - Click "Explore Sentinel-2 data" on this [page](https://dataspace.copernicus.eu/data-collections/copernicus-sentinel-data/sentinel-2) and create an account to login
 - In the explorer, make sure Sentinel-2 L2A is selected (Level 2A, atmospheric correction applied)
 - Scroll and zoom to the city of choice
 - Use the polygon tool (upper right corner, hover over pentagon icon and select rectangle) to draw a bounding box. Adjust until the extent approximates those in Schell et al. 2020. Try selecting the "False color" layer to help diagnose features to include or exclude
 - Set a threshold for cloud cover and select a date that reasonably approximates peak greenness. You may have to test multiple options to locate it, and not all cities will have the same date
 - Once the displayed images looks satisfactory, click "Find products for current view"
 - Check the desired product and download. It will take a while because the files are large
 
The data will be packaged as a zipped SAFE file in your Downloads folder. You may need to investigate the properties of the file and click 'unblock' to give permission to open. Once unzipped, you will find:
 - The images are jpeg2000 files nested within the GRANULE and IMG_DATA subfolders
 - Multiple resolutions and bands are available
 - Metadata is provided in `MTD_MSIL2A.xml`

For each city, locate the 10m resolution files for the B04 and B08 bands along with associated metadata and copy them to `data/city_name/` within this project. 

### Q3 (1 point)
Use the terra package and the `rast()` function to import the two bands, which are reported as digital numbers. 
Combine to calculate NDVI ($ (NIR - R) / (NIR + R)$) and display a quick plot of your first city. 

```{r}
# Read in data 
balt_R <- rast("data/baltimore/T18SUJ_20250603T155001_B04_10m_copy.jp2")
balt_NIR <- rast("data/baltimore/T18SUJ_20250603T155001_B08_10m_copy.jp2")
terra::crs(balt_R)
terra::crs(balt_NIR)

birm_R <- rast("data/birmingham /T16SEC_20190831T162839_B04_10m.jp2") 
birm_NIR <- rast("data/birmingham /T16SEC_20190831T162839_B08_10m.jp2") 

indy_R <- rast("data/indianapolis/T16TEK_20251003T163141_B04_10m.jp2")
indy_NIR <- rast("data/indianapolis/T16TEK_20251003T163141_B08_10m.jp2")

minn_R <- rast("data/minneapolis/T15TVK_20190808T170901_B04_10m.jp2")
minn_NIR <- rast("data/minneapolis/T15TVK_20190808T170901_B08_10m.jp2")

phe_R <- rast("data/pheonix/T12SUC_20221118T181641_B04_10m.jp2")
phe_NIR <- rast("data/pheonix/T12SUC_20221118T181641_B08_10m.jp2")
```

```{r}
# Calculate NDVI
balt_NDVI <- (balt_NIR - balt_R) / (balt_NIR + balt_R)

birm_NIR <- (birm_NIR - birm_R) / (birm_NIR + birm_R)

indy_NIR <- (indy_NIR - indy_R) / (indy_NIR + indy_R)

minn_NIR <- (minn_NIR - minn_R) / (minn_NIR + minn_R)

phe_NIR <- (phe_NIR - phe_R) / (phe_NIR + phe_R)

# Quick plot of first city 
plot(balt_NDVI)
```

### Bonus 1 (1 point)
Since you have 5 cities to plot, can you optimize the same operations as Q3 with a for loop? 

### Q4 (1 point)
Do the rasters and polygons share the same coordinate reference system? If not, project both into the same CRS and justify your choice. 

They do not share the same coordinate reference system. The polygon data (.json files) use the standard Geographic CRS (EPSG 4326), while the raster data (.jp2 files) use the Compound CRS (EPSG 8806). 
 
### Q5 (1 points)
Overlay the projected vector file onto the projected NDVI for a single city using `tidyterra::geom_spatraster()` in addition to `geom_sf()`. Adjust the color scales and add a scale bar to approximate Fig. 2a of Schell et al. 2020. 

### Q6 (1 point)
Repeat the above for all 5 cities and add the city name. Explore the `cowplot` or `patchwork` packages to create a multi-panel figure. 

### Q7 (2 points)
Now, let's examine the relationship between redlining and NDVI. Temporarily re-read in your redlining polygons using `terra:::vect()`. You can use `terra:extract()` on these temporary polygons within `mutate()` on your original polygons read in with `read_sf()`. Because the output of `terra::extract()` is a data.frame, `dplyr::pull()` can be helpful. 

Extract the mean, median, and central 95% quantile of NDVI from each delineated neighborhood while retaining the identity of the city. Perform your choice of at least two exploratory data visualizations utilizing different variables to evaluate this relationship and examine whether it differs between cities. 

### Bonus 2 (1 point)
Perform a statistical test to support your visual analysis above. 

### Q8 (2 points)
Create a final plot and describe whether NDVI is associated with historical redlining. Does this pattern differ between the five cities examined here? If so, how? 

### Bonus 3 (1 point)
Include the results of your statistical test in the final plot and use prose to incorporate statistical output in the context of the question above. 

